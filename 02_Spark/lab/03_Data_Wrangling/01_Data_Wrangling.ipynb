{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3854040d-4ce9-4a2c-abd8-1e02dde1d0b2",
   "metadata": {},
   "source": [
    "# 1. Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcb4e6b-bbf7-4fc3-b523-81235074a27b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeb6cb76-df54-46c8-8037-625d55049864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d8b7da7-ba9a-4b32-a4e9-76973564b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "498154e3-f7c7-4188-8391-38bbbe59ad0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/25 15:52:58 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Create or get a (new) SparkSession: session\n",
    "session = SparkSession.builder.appName(\"Wrangling Data\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695fae3b-06d6-447d-a0f7-64913a39b690",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed2aee7d-e305-454c-856e-663341d3cf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load the CSV file as a DataFrame\n",
    "path = \"../data/mini_sparkify_event_data.json\"\n",
    "user_log = session.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1d962b4-fd5a-451d-b14a-4555e7168c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register table view\n",
    "user_log.createOrReplaceTempView(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b8004f8-425b-45e0-8230-9724386177f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Table(name='logs', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]\n"
     ]
    }
   ],
   "source": [
    "# Print the list of tables in the SparkSession/catalog\n",
    "print(session.catalog.listTables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf4064-ce5a-4404-9dff-06bb781f8eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
